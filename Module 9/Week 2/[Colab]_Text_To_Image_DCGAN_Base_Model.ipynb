{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "K4h05EGvNRG3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 0Ô∏è‚É£ T·∫£i v√† gi·∫£i n√©n Flickr8k\n",
        "# ===========================\n",
        "def download_flickr8k(dataset_dir=\"Flickr8k\"):\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    # Danh s√°ch c√°c URL c·∫ßn t·∫£i\n",
        "    urls = {\n",
        "        \"images\": \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\",\n",
        "        \"captions\": \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\"\n",
        "    }\n",
        "\n",
        "    for key, url in urls.items():\n",
        "        zip_path = os.path.join(dataset_dir, f\"{key}.zip\")\n",
        "        extract_path = os.path.join(dataset_dir, key)\n",
        "\n",
        "        if not os.path.exists(extract_path):\n",
        "            print(f\"üì• Downloading {key} dataset...\")\n",
        "            urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "            print(f\"üìÇ Extracting {key} dataset...\")\n",
        "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(dataset_dir)\n",
        "\n",
        "            os.remove(zip_path)  # X√≥a file ZIP sau khi gi·∫£i n√©n\n",
        "\n",
        "    print(\"‚úÖ Dataset downloaded & extracted!\")\n",
        "\n",
        "download_flickr8k()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhbwkVKcNW5M",
        "outputId": "b6ce400c-8c82-4788-e9ed-a58e8b2edcaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading images dataset...\n",
            "üìÇ Extracting images dataset...\n",
            "üì• Downloading captions dataset...\n",
            "üìÇ Extracting captions dataset...\n",
            "‚úÖ Dataset downloaded & extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "captions_file = \"Flickr8k/Flickr8k.token.txt\"\n",
        "image_dir = \"Flickr8k/Flicker8k_Dataset\"  # Th∆∞ m·ª•c ch·ª©a ·∫£nh\n",
        "captions = {}\n",
        "text = []\n",
        "\n",
        "with open(captions_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        img_name = parts[0].split(\"#\")[0]\n",
        "\n",
        "        # N·∫øu c√≥ \".1\" ·ªü cu·ªëi file th√¨ lo·∫°i b·ªè\n",
        "        if img_name.endswith(\".1\"):\n",
        "            img_name = img_name[:-2]  # B·ªè k√Ω t·ª± \".1\" ·ªü cu·ªëi\n",
        "\n",
        "        # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: {img_name}\")  # C·∫£nh b√°o file b·ªã thi·∫øu\n",
        "            continue  # B·ªè qua file kh√¥ng t·ªìn t·∫°i\n",
        "\n",
        "        caption = parts[1].lower()\n",
        "        text.append(caption)\n",
        "\n",
        "        if img_name not in captions:\n",
        "            captions[img_name] = []\n",
        "        captions[img_name].append(caption)\n",
        "\n",
        "print(\"S·ªë l∆∞·ª£ng ·∫£nh h·ª£p l·ªá:\", len(captions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT77ZaWXApfq",
        "outputId": "1b01c0c4-3712-4358-ae57-8ae5de7be1b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "S·ªë l∆∞·ª£ng ·∫£nh h·ª£p l·ªá: 8091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm8Sk4fe-Lol",
        "outputId": "b5ca707c-fab1-4dae-ef02-21ee7e75366d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "captions['209605542_ca9cc52e7b.jpg']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNHPUOpQiEF6",
        "outputId": "53f526c6-2137-44c6-c114-7b2ecab0d572"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a climber wearing a red headband is pulling himself up some grey rocks high above some green foliage .',\n",
              " 'a man in a headband climbing a rock .',\n",
              " 'a man with a red headband climbing a rock cliff looming over greenery .',\n",
              " 'man climbing a sheet rock face .',\n",
              " 'man in red headband climbing a rock']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dnzvm_Q3i1ah",
        "outputId": "59d2d523-78d3-4e7c-c099-482fec22e151"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a child in a pink dress is climbing up a set of stairs in an entry way .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers, models\n",
        "\n",
        "# T·∫°o tokenizer d·∫°ng word-based\n",
        "tokenizer = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
        "\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "trainer = trainers.WordLevelTrainer(\n",
        "    vocab_size=10000,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"<pad>\", \"<unk>\"]\n",
        ")\n",
        "\n",
        "# Hu·∫•n luy·ªán tokenizer\n",
        "tokenizer.train_from_iterator(text, trainer)\n",
        "\n",
        "# L∆∞u tokenizer\n",
        "tokenizer.save(\"tokenizer.json\")\n",
        "\n",
        "# Load t·ª´ ƒëi·ªÉn t·ª´ tokenizer\n",
        "vocab = tokenizer.get_vocab()  # Tr√≠ch xu·∫•t t·ª´ ƒëi·ªÉn\n",
        "word_to_id = lambda word: vocab.get(word, vocab[\"<unk>\"])  # H√†m l·∫•y ID c·ªßa t·ª´"
      ],
      "metadata": {
        "id": "boJY-KNJiTzq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# Load tokenizer ƒë√£ train v√†o PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"tokenizer.json\",\n",
        "    unk_token=\"<unk>\", pad_token=\"<pad>\"\n",
        ")"
      ],
      "metadata": {
        "id": "EXCXXpN1jDJ2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"i go to school\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu80T3nAjG-5",
        "outputId": "e68142a8-dc4a-4386-8276-2a87c931e352"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1427, 526, 21, 750], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1Ô∏è‚É£ Load Flickr8k dataset\n",
        "# ===========================\n",
        "class Flickr8kDataset(Dataset):\n",
        "    def __init__(self, img_dir, captions, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load captions\n",
        "        self.captions = captions\n",
        "\n",
        "        self.img_names = list(self.captions.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        caption = np.random.choice(self.captions[img_name])  # Ch·ªçn caption ng·∫´u nhi√™n\n",
        "        encoded_caption = tokenizer(caption, padding=\"max_length\",\n",
        "                                    truncation=True, max_length=20, return_tensors=\"pt\")['input_ids'][0]\n",
        "        return {\n",
        "            'image': image,\n",
        "            'caption': encoded_caption\n",
        "        }"
      ],
      "metadata": {
        "id": "tfeziVvQN3lz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((8, 8)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "dataset = Flickr8kDataset(\n",
        "    img_dir=\"/content/Flickr8k/Flicker8k_Dataset\",\n",
        "    captions=captions,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "K7ays76xN9pF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(dataset))\n",
        "\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9FulO3pj9TR",
        "outputId": "2a1ea0b1-90b4-4638-c949-7c6361a2d018"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[-0.0824, -0.3412, -0.2471, -0.2706, -0.3647, -0.4196, -0.2549,\n",
              "           -0.5294],\n",
              "          [-0.2863, -0.5137, -0.1451, -0.2078, -0.4118, -0.4431, -0.2157,\n",
              "           -0.5373],\n",
              "          [-0.0902, -0.1765, -0.1608, -0.2471, -0.3490, -0.3255, -0.1059,\n",
              "           -0.4667],\n",
              "          [ 0.4510,  0.1529, -0.0824, -0.2471, -0.2863, -0.3333, -0.0902,\n",
              "           -0.2235],\n",
              "          [ 0.2157, -0.1059, -0.1529, -0.2235, -0.2392, -0.2627, -0.2314,\n",
              "           -0.3490],\n",
              "          [-0.5843, -0.7333, -0.5373, -0.3412, -0.2706, -0.2078, -0.0667,\n",
              "           -0.3098],\n",
              "          [-0.2549, -0.4431, -0.4902, -0.4824, -0.6863, -0.5686, -0.3176,\n",
              "           -0.3333],\n",
              "          [ 0.3255, -0.0353, -0.3255, -0.2863,  0.0196, -0.4118, -0.5529,\n",
              "           -0.1216]],\n",
              " \n",
              "         [[-0.0353, -0.4275, -0.3490, -0.3882, -0.5373, -0.5373, -0.3333,\n",
              "           -0.5137],\n",
              "          [-0.3333, -0.5922, -0.3255, -0.3647, -0.4980, -0.4902, -0.2784,\n",
              "           -0.4824],\n",
              "          [-0.2627, -0.3098, -0.3961, -0.4431, -0.4745, -0.3961, -0.1294,\n",
              "           -0.4118],\n",
              "          [-0.0118, -0.1294, -0.3333, -0.4510, -0.4039, -0.4196, -0.1686,\n",
              "           -0.1843],\n",
              "          [-0.1529, -0.3882, -0.3725, -0.4431, -0.4588, -0.4667, -0.3882,\n",
              "           -0.4275],\n",
              "          [-0.6314, -0.7725, -0.6235, -0.5294, -0.4980, -0.4510, -0.2941,\n",
              "           -0.4667],\n",
              "          [-0.3490, -0.5059, -0.5529, -0.5529, -0.6235, -0.6706, -0.5137,\n",
              "           -0.4431],\n",
              "          [ 0.0353, -0.2078, -0.3961, -0.3255,  0.0510, -0.5373, -0.6078,\n",
              "            0.0275]],\n",
              " \n",
              "         [[-0.1843, -0.5843, -0.5294, -0.5922, -0.7333, -0.7020, -0.5608,\n",
              "           -0.7490],\n",
              "          [-0.5137, -0.7412, -0.5451, -0.5686, -0.6471, -0.6235, -0.5373,\n",
              "           -0.7333],\n",
              "          [-0.4667, -0.4588, -0.6157, -0.6549, -0.6392, -0.5216, -0.4118,\n",
              "           -0.6392],\n",
              "          [-0.1137, -0.1608, -0.5373, -0.6471, -0.5608, -0.5373, -0.3647,\n",
              "           -0.4431],\n",
              "          [-0.1686, -0.4039, -0.5451, -0.6235, -0.6549, -0.6549, -0.6157,\n",
              "           -0.6471],\n",
              "          [-0.6941, -0.8353, -0.7098, -0.7098, -0.7020, -0.6784, -0.6000,\n",
              "           -0.7020],\n",
              "          [-0.5451, -0.6235, -0.6471, -0.6863, -0.7647, -0.8275, -0.7098,\n",
              "           -0.5922],\n",
              "          [-0.3569, -0.4588, -0.5451, -0.4431, -0.0353, -0.6863, -0.6549,\n",
              "            0.1765]]]),\n",
              " 'caption': tensor([   2,   41,   19,  121,   66,    2,  199, 2590,    3,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbXQU6RKjrXc",
        "outputId": "923197b3-f200-4346-eec2-a9be26114a4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['caption'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bti1bRqSjtcI",
        "outputId": "3933963d-eef2-43b2-f2a6-3d719d33a453"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2Ô∏è‚É£ Word Embeddings + LSTM\n",
        "# ===========================\n",
        "class embedding_text(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(embedding_text, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, captions):\n",
        "        embeds = self.embedding(captions)\n",
        "        _, (hidden, _) = self.lstm(embeds)\n",
        "        return hidden[-1]\n",
        "\n",
        "# ===========================\n",
        "# 3Ô∏è‚É£ DCGAN Model\n",
        "# ===========================\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, embed_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + embed_dim, 128 * 4 * 4),\n",
        "            #       latent_dim (64) + embed_dim (256)\n",
        "            # Input:(batch_size,320) - Output:(batch_size,512)\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            # Input:(batch_size,512) - Output:(batch_size,128,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            # Input:(batch_size,128,4,4) - Output:(batch_size,64, 8, 8)\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),\n",
        "            # Input:(batch_size,64, 8, 8) - Output:(batch_size, 3, 8, 8)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, caption_embed):\n",
        "        x = torch.cat((noise, caption_embed), dim=1)\n",
        "        #  (batch_size,64) + (batch_size,256) = (batch_size,320)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
        "            # Input:(batch_size,3,8,8) - Output:(batch_size,64,4,4)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64 ,128 ,3 , stride=2, padding=1),\n",
        "            # Input:(batch_size,64,4,4) - Output:(batch_size,128,2,2)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten()\n",
        "            # Input:(batch_size,128,2,2) - Output:(batch_size,512)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(512 + embed_dim, 1)\n",
        "        # Input:(batch_size,512) - Output:(batch_size,1)\n",
        "\n",
        "    def forward(self, img, caption_embed):\n",
        "        img_features = self.cnn(img)\n",
        "        x = torch.cat((img_features, caption_embed), dim=1)\n",
        "        #  (batch_size,512) + (batch_size,256) = (batch_size,768)\n",
        "        return torch.sigmoid(self.fc(x))\n"
      ],
      "metadata": {
        "id": "YL6B1MqPGOAt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAnykd8rQMBU",
        "outputId": "b5db84d9-6ccb-4df2-938c-17efd02dfbfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5167"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Model\n",
        "generator = Generator(64, 256).to(device)\n",
        "discriminator = Discriminator(256).to(device)\n",
        "embedding_text = embedding_text(len(tokenizer), 256, 256).to(device)\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "2FoN_8oYkcig"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkyUvuChkekS",
        "outputId": "6728aed3-6cda-4a9b-9d9d-eaf2a364585f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "embedding_text(\n",
              "  (embedding): Embedding(5167, 256)\n",
              "  (lstm): LSTM(256, 256, batch_first=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtmLRlbdkgNI",
        "outputId": "54f67c5a-88ee-456c-b394-752bf92abb6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=320, out_features=2048, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Unflatten(dim=1, unflattened_size=(128, 4, 4))\n",
              "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz4EN11kklTf",
        "outputId": "8cbeec81-8828-44db-f57a-e8e1883ff45d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (4): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "batch_sample = next(iter(dataloader))\n",
        "\n",
        "batch_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqkwMfaukwRB",
        "outputId": "7169de4e-f418-4d54-a45a-7ace27bb288a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[[-0.5529, -0.8353, -0.8275,  ..., -0.6863, -0.7490, -0.7333],\n",
              "           [-0.5922, -0.7098, -0.7176,  ..., -0.5294, -0.8275, -0.8510],\n",
              "           [-0.4431, -0.2784, -0.1529,  ..., -0.1451, -0.8118, -0.8824],\n",
              "           ...,\n",
              "           [ 0.3569,  0.3333,  0.4196,  ...,  0.3882,  0.3412,  0.3176],\n",
              "           [ 0.3020,  0.3176,  0.3333,  ...,  0.3647,  0.3725,  0.3647],\n",
              "           [ 0.3333,  0.3255,  0.3020,  ...,  0.3725,  0.3961,  0.3804]],\n",
              " \n",
              "          [[-0.4510, -0.7569, -0.7333,  ..., -0.6314, -0.7020, -0.6941],\n",
              "           [-0.5294, -0.7412, -0.7098,  ..., -0.6314, -0.7725, -0.7804],\n",
              "           [-0.4510, -0.5137, -0.3490,  ..., -0.4196, -0.7569, -0.8118],\n",
              "           ...,\n",
              "           [ 0.3725,  0.2157,  0.3804,  ...,  0.4275,  0.3647,  0.3333],\n",
              "           [ 0.3647,  0.3804,  0.3961,  ...,  0.3882,  0.3882,  0.3882],\n",
              "           [ 0.4039,  0.4039,  0.3882,  ...,  0.4039,  0.3961,  0.3804]],\n",
              " \n",
              "          [[-0.5216, -0.8667, -0.8431,  ..., -0.7725, -0.7961, -0.7882],\n",
              "           [-0.7412, -0.8431, -0.7961,  ..., -0.7412, -0.8588, -0.8824],\n",
              "           [-0.6471, -0.6549, -0.4353,  ..., -0.4902, -0.8588, -0.9137],\n",
              "           ...,\n",
              "           [-0.0902, -0.2392, -0.0275,  ..., -0.0039, -0.1451, -0.1529],\n",
              "           [-0.2078, -0.1922, -0.0667,  ...,  0.0196, -0.0902, -0.1137],\n",
              "           [-0.1294, -0.1451, -0.1843,  ..., -0.0902, -0.0667, -0.1059]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1843, -0.1294, -0.5843,  ..., -0.5843, -0.7804, -0.8824],\n",
              "           [-0.2627, -0.3098, -0.5608,  ..., -0.5843, -0.7882, -0.8667],\n",
              "           [-0.4431, -0.4275, -0.4039,  ..., -0.5294, -0.7412, -0.8745],\n",
              "           ...,\n",
              "           [-0.8667, -0.7804, -0.2157,  ..., -0.6235, -0.5608, -0.8275],\n",
              "           [-0.8588, -0.7725, -0.1216,  ..., -0.7569, -0.6078, -0.5843],\n",
              "           [-0.8667, -0.7882, -0.3804,  ..., -0.8667, -0.8118, -0.6784]],\n",
              " \n",
              "          [[ 0.2784, -0.0588, -0.5843,  ..., -0.6392, -0.7961, -0.8745],\n",
              "           [-0.2549, -0.3569, -0.5843,  ..., -0.6471, -0.7961, -0.8510],\n",
              "           [-0.4353, -0.4745, -0.4745,  ..., -0.6078, -0.7647, -0.8745],\n",
              "           ...,\n",
              "           [-0.8745, -0.7961, -0.3176,  ..., -0.6627, -0.6078, -0.8196],\n",
              "           [-0.8588, -0.7961, -0.2235,  ..., -0.7961, -0.6549, -0.6078],\n",
              "           [-0.8745, -0.8118, -0.4588,  ..., -0.8745, -0.8039, -0.6706]],\n",
              " \n",
              "          [[ 0.3255, -0.0824, -0.7176,  ..., -0.8902, -0.9294, -0.9608],\n",
              "           [-0.5137, -0.6000, -0.8118,  ..., -0.8902, -0.9451, -0.9608],\n",
              "           [-0.8980, -0.8667, -0.8118,  ..., -0.8745, -0.9216, -0.9608],\n",
              "           ...,\n",
              "           [-0.8902, -0.8353, -0.4353,  ..., -0.7961, -0.8745, -0.9137],\n",
              "           [-0.9137, -0.8353, -0.3804,  ..., -0.8824, -0.9059, -0.8980],\n",
              "           [-0.9451, -0.8588, -0.5843,  ..., -0.9216, -0.9373, -0.9137]]],\n",
              " \n",
              " \n",
              "         [[[-0.6863, -0.6392, -0.5765,  ..., -0.4118, -0.3255, -0.3569],\n",
              "           [-0.6863, -0.5922, -0.4667,  ..., -0.3020, -0.1137, -0.2549],\n",
              "           [-0.2157, -0.1686, -0.1451,  ..., -0.0902,  0.0039, -0.0118],\n",
              "           ...,\n",
              "           [ 0.3176,  0.2392,  0.2000,  ...,  0.1608,  0.1373,  0.0980],\n",
              "           [ 0.7961,  0.6392,  0.5843,  ...,  0.0431,  0.1373,  0.0667],\n",
              "           [ 0.3725,  0.3882,  0.4275,  ..., -0.0588,  0.0431,  0.0196]],\n",
              " \n",
              "          [[-0.5608, -0.5137, -0.4588,  ..., -0.3176, -0.2392, -0.2863],\n",
              "           [-0.5686, -0.4745, -0.3725,  ..., -0.2471, -0.1373, -0.2549],\n",
              "           [-0.1137, -0.0745, -0.0510,  ..., -0.0980,  0.0588,  0.0275],\n",
              "           ...,\n",
              "           [ 0.4745,  0.4196,  0.3961,  ...,  0.3647,  0.3412,  0.3098],\n",
              "           [ 0.8196,  0.6863,  0.6549,  ...,  0.1765,  0.3176,  0.2549],\n",
              "           [ 0.4745,  0.5059,  0.5373,  ...,  0.0745,  0.2235,  0.2000]],\n",
              " \n",
              "          [[-0.5922, -0.5529, -0.5137,  ..., -0.4275, -0.3725, -0.3176],\n",
              "           [-0.5765, -0.5294, -0.4588,  ..., -0.3647, -0.2314, -0.2706],\n",
              "           [-0.0824, -0.1529, -0.2000,  ..., -0.2392, -0.1686, -0.1686],\n",
              "           ...,\n",
              "           [ 0.6157,  0.5686,  0.5373,  ...,  0.5137,  0.4980,  0.4667],\n",
              "           [ 0.8510,  0.7412,  0.7020,  ...,  0.2627,  0.4588,  0.4118],\n",
              "           [ 0.5765,  0.6000,  0.6314,  ...,  0.1686,  0.3725,  0.3647]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.3804, -0.9216, -0.9922,  ..., -0.9529, -0.9137, -0.6627],\n",
              "           [-0.1608, -0.6784, -0.8745,  ..., -0.7647, -0.8118, -0.7725],\n",
              "           [-0.8196, -0.9451, -0.7569,  ..., -0.6235, -0.7412, -0.6941],\n",
              "           ...,\n",
              "           [-0.8588, -0.5451, -0.4588,  ..., -0.6235, -0.8275, -0.8745],\n",
              "           [-0.7569, -0.7255, -0.4902,  ..., -0.7176, -0.6314, -0.8196],\n",
              "           [-0.8745, -0.8824, -0.7020,  ..., -0.6549, -0.8353, -0.7333]],\n",
              " \n",
              "          [[-0.4353, -0.9451, -0.9922,  ..., -0.9608, -0.9373, -0.7725],\n",
              "           [-0.2000, -0.7647, -0.8902,  ..., -0.8353, -0.8588, -0.8118],\n",
              "           [-0.8275, -0.9451, -0.7804,  ..., -0.7020, -0.8431, -0.7255],\n",
              "           ...,\n",
              "           [-0.8824, -0.6549, -0.4275,  ..., -0.6471, -0.8510, -0.8824],\n",
              "           [-0.7412, -0.7098, -0.4275,  ..., -0.7255, -0.7412, -0.8588],\n",
              "           [-0.8667, -0.8824, -0.6784,  ..., -0.6314, -0.8510, -0.7647]],\n",
              " \n",
              "          [[-0.5059, -0.9529, -0.9922,  ..., -0.9608, -0.9451, -0.8118],\n",
              "           [-0.2549, -0.8196, -0.8980,  ..., -0.8667, -0.8824, -0.8039],\n",
              "           [-0.8353, -0.9451, -0.7882,  ..., -0.7490, -0.8824, -0.7255],\n",
              "           ...,\n",
              "           [-0.8824, -0.6314, -0.3882,  ..., -0.6706, -0.8431, -0.8824],\n",
              "           [-0.7333, -0.7020, -0.3882,  ..., -0.7255, -0.7176, -0.8510],\n",
              "           [-0.8745, -0.8902, -0.6627,  ..., -0.6235, -0.8431, -0.7490]]],\n",
              " \n",
              " \n",
              "         [[[ 0.7647,  0.0667,  0.0196,  ..., -0.1686, -0.4902, -0.4118],\n",
              "           [ 0.4118,  0.1059,  0.2314,  ...,  0.0745, -0.3647, -0.3961],\n",
              "           [-0.0431, -0.0353, -0.2392,  ..., -0.1216, -0.2235, -0.2706],\n",
              "           ...,\n",
              "           [-0.1686, -0.2392, -0.1216,  ..., -0.3961, -0.1686, -0.1922],\n",
              "           [-0.1529, -0.2157, -0.0824,  ..., -0.1373, -0.1294, -0.1216],\n",
              "           [ 0.0039, -0.0980,  0.0118,  ...,  0.1843,  0.1216,  0.0196]],\n",
              " \n",
              "          [[ 0.8196,  0.1922,  0.2471,  ...,  0.0353, -0.1608, -0.1608],\n",
              "           [ 0.4118,  0.1059,  0.3255,  ...,  0.1216, -0.0667, -0.1529],\n",
              "           [-0.1765, -0.2471, -0.3098,  ..., -0.0667, -0.0510, -0.0667],\n",
              "           ...,\n",
              "           [-0.2471, -0.3098, -0.2078,  ..., -0.4431, -0.2549, -0.3020],\n",
              "           [-0.2078, -0.2784, -0.1686,  ..., -0.2000, -0.2000, -0.2000],\n",
              "           [-0.0353, -0.1373, -0.0745,  ...,  0.0980,  0.0353, -0.0667]],\n",
              " \n",
              "          [[ 0.7020, -0.0824, -0.1529,  ..., -0.2941, -0.6314, -0.5059],\n",
              "           [ 0.3569,  0.0196,  0.2392,  ..., -0.0196, -0.5451, -0.5216],\n",
              "           [-0.2235, -0.2863, -0.3490,  ..., -0.3490, -0.5216, -0.6078],\n",
              "           ...,\n",
              "           [-0.3490, -0.3961, -0.3176,  ..., -0.4902, -0.3412, -0.3882],\n",
              "           [-0.3490, -0.3882, -0.2863,  ..., -0.3020, -0.3098, -0.3176],\n",
              "           [-0.2392, -0.3098, -0.2000,  ..., -0.0353, -0.1059, -0.2000]]],\n",
              " \n",
              " \n",
              "         [[[-0.6706, -0.7490, -0.8196,  ..., -0.3804, -0.3725, -0.5294],\n",
              "           [-0.4353, -0.3098, -0.1294,  ...,  0.3647,  0.5608, -0.0196],\n",
              "           [ 0.6000,  0.7725,  0.7725,  ...,  0.4980,  0.1608, -0.4902],\n",
              "           ...,\n",
              "           [ 0.2157,  0.5686,  0.3961,  ...,  0.0196,  0.0667,  0.5059],\n",
              "           [-0.3725, -0.2314, -0.6000,  ..., -0.3804,  0.0588,  0.2549],\n",
              "           [-0.2863, -0.2314, -0.4980,  ..., -0.5529, -0.1843, -0.1922]],\n",
              " \n",
              "          [[-0.6235, -0.7098, -0.7804,  ..., -0.4980, -0.4275, -0.5216],\n",
              "           [-0.4353, -0.3176, -0.1922,  ..., -0.0510,  0.3490, -0.0588],\n",
              "           [ 0.5216,  0.7255,  0.7176,  ...,  0.3961,  0.1294, -0.5451],\n",
              "           ...,\n",
              "           [ 0.1059,  0.4902,  0.3647,  ...,  0.1686,  0.0118,  0.1765],\n",
              "           [-0.5686, -0.4667, -0.7490,  ..., -0.1686, -0.0275, -0.0510],\n",
              "           [-0.5843, -0.5294, -0.6627,  ..., -0.4039, -0.4275, -0.4824]],\n",
              " \n",
              "          [[-0.6078, -0.6863, -0.8118,  ..., -0.5765, -0.4745, -0.5294],\n",
              "           [-0.4510, -0.3255, -0.2157,  ..., -0.1843,  0.2863, -0.0196],\n",
              "           [ 0.5373,  0.7412,  0.7098,  ...,  0.5137,  0.2627, -0.5294],\n",
              "           ...,\n",
              "           [ 0.0667,  0.4745,  0.3569,  ...,  0.4431,  0.0980,  0.0039],\n",
              "           [-0.7255, -0.6471, -0.8667,  ...,  0.1843, -0.0431, -0.3020],\n",
              "           [-0.8353, -0.7882, -0.7961,  ..., -0.1216, -0.5373, -0.6863]]]]),\n",
              " 'caption': tensor([[   2,   28,    8,  ...,    0,    0,    0],\n",
              "         [  24,   10, 1958,  ...,    0,    0,    0],\n",
              "         [   2,  246, 1168,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [   5,   13,   27,  ...,   20,  371,   17],\n",
              "         [   2,  548,    4,  ...,    0,    0,    0],\n",
              "         [   2,   11,    4,  ...,    0,    0,    0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sample['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRoBjbvtkS-P",
        "outputId": "96baec02-8ba3-4078-a0f4-f1abe434f3d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sample['caption'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOz3u7hNlJ_Y",
        "outputId": "20166cac-420b-4cce-ba30-b21f4b2f152a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caption_embeddings = embedding_text(batch_sample['caption'].to(device))\n",
        "\n",
        "caption_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjCgzQvNk-Po",
        "outputId": "5b295b22-3f0e-4886-a605-571975d65f0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(batch_sample['image'].size(0), 64, device=device)\n",
        "fake_images = generator(noise, caption_embeddings)\n",
        "\n",
        "fake_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5LwWBCvUW1j",
        "outputId": "5bf4c3c3-81c4-4ef1-fccb-b9cd8cffcac2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch in dataloader:\n",
        "        # load tensor images\n",
        "        images = batch['image'].to(device)\n",
        "        # load one-hot vector tokenizer\n",
        "        captions = batch['caption'].to(device)\n",
        "\n",
        "        caption_embeddings = embedding_text(captions)\n",
        "        #  (batch_size, 256)\n",
        "        noise = torch.randn(images.size(0), 64, device=device)\n",
        "        #  (batch_size, 64)\n",
        "\n",
        "        fake_images = generator(noise, caption_embeddings)\n",
        "        #  (batch_size, 3, 8, 8)\n",
        "        real_labels = torch.ones(images.size(0), 1, device=device)\n",
        "        #  (batch_size, 1)\n",
        "        fake_labels = torch.zeros(images.size(0), 1, device=device)\n",
        "        #  (batch_size, 1)\n",
        "\n",
        "        real_loss = criterion(discriminator(images, caption_embeddings), real_labels)\n",
        "        fake_loss = criterion(discriminator(fake_images.detach(), caption_embeddings), fake_labels)\n",
        "        '''    Detaches fake_images from the computation graph so that gradients\n",
        "        do not flow back to the generator during Discriminator training.     '''\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        #  retain_graph=True\n",
        "        optimizer_D.step()\n",
        "\n",
        "        g_loss = criterion(discriminator(fake_images, caption_embeddings), real_labels)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/5], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uJGjk1DiqQc",
        "outputId": "9a6a2b72-31b1-4219-c6f3-3422a9148b18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], D Loss: 1.1546542644500732, G Loss: 1.007249116897583\n",
            "Epoch [2/5], D Loss: 1.2401411533355713, G Loss: 1.0086605548858643\n",
            "Epoch [3/5], D Loss: 1.4049007892608643, G Loss: 0.8909916877746582\n",
            "Epoch [4/5], D Loss: 1.4413191080093384, G Loss: 0.7599515914916992\n",
            "Epoch [5/5], D Loss: 1.1590051651000977, G Loss: 0.8860763907432556\n"
          ]
        }
      ]
    }
  ]
}