# -*- coding: utf-8 -*-
"""M7-W3-2-Object-Counting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K2pSSbZbfrbGmQVmcfBITsNsNGaT0Kbs
"""

!pip install ultralytics

import cv2
from ultralytics import solutions

# Mở file video cần xử lý
cap = cv2.VideoCapture("/content/thai.mp4")
assert cap.isOpened(), "Error reading video file"

# Lấy thông tin video
w, h, fps = (
    int(cap.get(x))
    for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS)
)

# Định nghĩa các điểm tạo thành vùng đếm
# region_points = [(20, 400), (1080, 400)]  # Đếm đối tượng qua một đường thẳng
region_points = [
    (430, 700),  # Góc trên bên trái
    (1600, 700), # Góc trên bên phải
    (1600, 1080), # Góc dưới bên phải
    (430, 1080),  # Góc dưới bên trái
]  # Vùng đếm hình chữ nhật: top left, top right, bottom right, bottom left

# Video writer
video_writer = cv2.VideoWriter(
    "./run/thai_counted.mp4",
    cv2.VideoWriter_fourcc(*"mp4v"),
    fps,
    (w, h)
)

# Init ObjectCounter
counter = solutions.ObjectCounter(
    show=False,  # Không hiển thị đầu ra
    region=region_points,  # Truyền các điểm khu vực đếm
    model="yolo11x.pt",  # Sử dụng mô hình YOLO11x cho việc đếm đối tượng
    # Nếu muốn dùng mô hình YOLO11 OBB (Oriented Bounding Boxes), sử dụng:
    # model="yolo11n-obb.pt"
)

# Process video
while cap.isOpened():
    success, im0 = cap.read()
    if not success:
        print("Video frame is empty or video processing has been successfully completed.")
        break

    # Đếm đối tượng và theo dõi với YOLO
    results = model.track(im0, persist=True, show=False)

    # Lấy kết quả và vẽ lên khung hình
    im0 = results[0].plot()

    # Ghi video đã xử lý
    video_writer.write(im0)

# Giải phóng tài nguyên
cap.release()
video_writer.release()
cv2.destroyAllWindows()

import cv2
from matplotlib import pyplot as plt

# Đọc video
video_path = '/content/run/thai_tracked.mp4'
cap = cv2.VideoCapture(video_path)

# Lấy một khung hình cụ thể (ví dụ, lấy khung hình đầu tiên)
ret, frame = cap.read()
cap.release()

if ret:
    # Xử lý khung hình bằng YOLO (nếu cần)
    results = model.track(frame, persist=True, show=False)

    # Lấy khung hình đã xử lý
    processed_frame = results[0].plot()

    # Chuyển đổi từ BGR sang RGB để hiển thị trong matplotlib
    processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)

    # Hiển thị ảnh bằng matplotlib
    plt.imshow(processed_frame_rgb)
    plt.axis('off')  # Tắt trục
    plt.show()

else:
    print("Không thể đọc video!")