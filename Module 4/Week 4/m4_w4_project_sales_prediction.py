# -*- coding: utf-8 -*-
"""M4_W4_Project_Sales_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4tlup7-5i29X60Pg0sEfl2k8eDzB9q9

1. Linear regression
"""

import numpy as np

class CustomLinearRegression:
    def __init__(self, X_data, y_target, learning_rate=0.01, num_epochs=10000):
        self.num_samples = X_data.shape[0]
        self.X_data = np.c_[np.ones((self.num_samples, 1)), X_data]
        self.y_target = y_target
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs

        # Initial weights
        self.theta = np.random.randn(self.X_data.shape[1], 1)
        self.losses = []

    def compute_loss(self, y_pred, y_target):
        # Mean Squared Error (MSE) loss
        loss = np.sum((y_pred - y_target) ** 2) / (2 * self.num_samples)
        return loss

    def predict(self, X_data):
        # Predict by applying the linear model
        y_pred = X_data.dot(self.theta)
        return y_pred

    def fit(self):
        for epoch in range(self.num_epochs):
            # Step 1: Predict
            y_pred = self.predict(self.X_data)

            # Step 2: Compute loss
            loss = self.compute_loss(y_pred, self.y_target)
            self.losses.append(loss)

            # Step 3: Compute gradients
            loss_grd = 2 * (y_pred - self.y_target) / self.num_samples
            gradients = self.X_data.T.dot(loss_grd)

            # Step 4: Update weights
            self.theta = self.theta - self.learning_rate * gradients

            if (epoch % 50) == 0:
                print(f'Epoch: {epoch} - Loss: {loss}')

        return {
            'loss': sum(self.losses) / len(self.losses),
            'weight': self.theta
        }

import numpy as np

def r2score(y_pred, y):
    rss = np.sum((y_pred - y) ** 2)      # Residual Sum of Squares
    tss = np.sum((y - y.mean()) ** 2)    # Total Sum of Squares
    r2 = 1 - (rss / tss)
    return r2

# Case 1
y_pred_1 = np.array([1, 2, 3, 4, 5])
y_1 = np.array([1, 2, 3, 4, 5])
r2_case_1 = r2score(y_pred_1, y_1)
print("R² for Case 1:", r2_case_1)

# Case 2
y_pred_2 = np.array([1, 2, 3, 4, 5])
y_2 = np.array([3, 5, 5, 2, 4])
r2_case_2 = r2score(y_pred_2, y_2)
print("R² for Case 2:", r2_case_2)

"""2. Polynomial Regression"""

import numpy as np

def create_polynomial_features(X, degree=2):
    """Creates the polynomial features.

    Args:
        X: A 2D numpy array for the data.
        degree: An integer for the degree of the generated polynomial function.

    Returns:
        X_new: A 2D numpy array containing the polynomial features.
    """
    X_new = X
    for d in range(2, degree + 1):
        X_new = np.c_[X_new, np.power(X, d)]
    return X_new

# Input example
X = np.array([[1], [2], [3]])
X_poly = create_polynomial_features(X, degree=2)
print("Polynomial Features:\n", X_poly)

import numpy as np

# Input data
X = np.array([[1, 2], [2, 3], [3, 4]])
degree = 2

def create_polynomial_features(X, degree=2):
    X_mem = []
    for X_sub in X.T:
        X_sub = X_sub.T
        X_new = X_sub
        for d in range(2, degree + 1):
            X_new = np.c_[X_sub, np.power(X_sub, d)]
        X_mem.extend(X_new.T)
    return np.c_[X_mem].T

# Option A
def create_polynomial_features_A(X, degree=2):
    X_mem = []
    for X_sub in X.T:
        X_new = X_sub
        for d in range(2, degree + 1):
            X_new = np.c_[X_new, np.power(X_sub, d)]
        X_mem.extend(X_new.T)
    return np.c_[X_mem].T

# Option B
def create_polynomial_features_B(X, degree=2):
    X_mem = []
    for X_sub in X.T:
        X_sub = X_sub.T
        X_new = X_sub
        for d in range(2, degree + 1):
            X_new = np.c_[X_new, np.power(X_sub, d)]
        X_mem.append(X_new.T)
    return np.c_[X_mem].T

# Option C
def create_polynomial_features_C(X, degree=2):
    X_mem = []
    for X_sub in X.T:
        X_sub = X_sub.T
        X_new = X_sub
        for d in range(2, degree + 1):
            X_new = np.c_[X_sub, np.power(X_sub, d)]
        X_mem.extend(X_new.T)
    return np.c_[X_mem].T

# Option D
def create_polynomial_features_D(X, degree=2):
    X_mem = []
    for X_sub in X.T:
        X_sub = X_sub.T
        X_new = X_sub
        for d in range(2, degree + 1):
            X_new = np.c_[X_new, np.power(X_sub, d)]
        X_mem.extend(X_new.T)
    return np.c_[X_mem].T

# Run each option and print results
print("Option A:\n", create_polynomial_features_A(X, degree))
print("Option B:\n", create_polynomial_features_B(X, degree))
print("Option C:\n", create_polynomial_features_C(X, degree))
print("Option D:\n", create_polynomial_features_D(X, degree))

"""3. Sales Prediction"""

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/SalesPrediction.csv')

# Kiểm tra dữ liệu
print(df.head())
print(df.info())

# Apply One Hot Encoding on 'Influencer' column
df = pd.get_dummies(df, columns=['Influencer'])

# Fill missing values with the mean
df = df.fillna(df.mean())

from sklearn.model_selection import train_test_split

# Define features and target variable
X = df[['TV', 'Radio', 'Social Media', 'Influencer_Macro', 'Influencer_Mega', 'Influencer_Micro', 'Influencer_Nano']]
y = df[['Sales']]

# Train Test Split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.33,
    random_state=0
)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_processed = scaler.fit_transform(X_train)
scaler.mean_[0]

from sklearn.preprocessing import PolynomialFeatures

poly_features = PolynomialFeatures(degree=2)
X_train_poly = poly_features.fit_transform(X_train_processed)
X_test_poly = poly_features.transform(X_test_processed)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train)  # Huấn luyện mô hình trên tập huấn luyện đa thức
preds = poly_model.predict(X_test_poly)  # Dự đoán trên tập kiểm tra
r2 = r2_score(y_test, preds)  # Tính toán R² score để đánh giá hiệu suất mô hình

print("R² score:", r2)